# ğŸ¥ Healthcare PDF Chatbot â€“ Chat With Medical Documents Using AI

This project enables users to **interact with healthcare PDF documents** using a conversational AI interface.  
Upload any medical PDF and ask questions â€” the chatbot answers directly from the document using **RAG (Retrieval-Augmented Generation)**.

It leverages **PDF parsing**, **chunking**, **semantic retrieval**, **vector search**, and a **powerful GROQ LLM** to provide accurate, source-based answers.

---

## ğŸš€ Features

- ğŸ“„ Upload any healthcare PDF
- ğŸ’¬ Ask questions from uploaded document
- ğŸ§  Semantic search using embeddings
- âš¡ Fast responses via GROQ LLM
- ğŸ“š FAISS vector database storage
- ğŸ” Retrieves relevant document chunks
- ğŸ–¥ï¸ Clean Streamlit chat interface
- ğŸ’¾ Automatically saves uploaded PDFs
- ğŸ”„ Real-time indexing and querying
- ğŸ“ Source-based answers from document
- ğŸ§¾ Separate PDF upload & indexing module

---

## ğŸ› ï¸ Tech Stack

| Component        | Technology                          |
|------------------|-------------------------------------|
| UI               | Streamlit                           |
| LLM              | GROQ (Llama3 / Mixtral)             |
| Framework        | LlamaIndex + LangChain              |
| Embeddings       | HuggingFace SentenceTransformers    |
| Vector Store     | FAISS                               |
| PDF Handling     | PyPDF                               |
| Backend          | Python                              |

---

## ğŸ”— Workflow Overview

### 1ï¸âƒ£ ğŸ“„ PDF Upload â†’ Storage  
- User uploads PDF from Streamlit UI  
- File saved automatically inside `data/` folder  
- Separate upload module ensures persistent storage  

### 2ï¸âƒ£ ğŸ“š Text Extraction  
- PDF parsed using **PyPDF**  
- Raw text extracted from all pages  

### 3ï¸âƒ£ âœ‚ï¸ Text Chunking  
- Text split into smaller chunks  
- Improves retrieval accuracy  
- Optimized for semantic search  

### 4ï¸âƒ£ ğŸ§  Embedding Generation  
- Each chunk converted into embeddings  
- Using **HuggingFace SentenceTransformers**  

### 5ï¸âƒ£ ğŸ—‚ï¸ Vector Database Creation  
- Embeddings stored in **FAISS vector store**  
- Enables fast similarity search  

### 6ï¸âƒ£ â“ User Question  
- User asks question in chat UI  

### 7ï¸âƒ£ ğŸ” Retrieval  
- Relevant chunks retrieved from FAISS  
- Context passed to LLM  

### 8ï¸âƒ£ ğŸ¤– Answer Generation  
- GROQ LLM generates final response  
- Uses retrieved document context  
- Ensures source-based answers  

### 9ï¸âƒ£ ğŸ’¬ Streamlit Chat UI  
- Chat interface shows answer  
- Continuous conversation supported  
- Clean UI for interaction  

---

## ğŸ“ Project Structure

---

## ğŸ› ï¸ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/Mayanknarwal0506/RAG_Healthcare_Chatbot.git
cd RAG_Healthcare_Chatbot
```

2. **Create a virtual environment (optional but recommended):**

```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On Unix/Mac
source venv/bin/activate
```

3. **Install the dependencies:**

```bash
pip install -r requirements.txt
```
4. **Start the Streamlit app:**

```bash
streamlit run app.py
```

5. **Visit in your browser:**

```bash
http://localhost:8501
```

